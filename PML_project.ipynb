{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cRZ4_oJjGlB"
   },
   "source": [
    "# **Practical Machine Learning Project**\n",
    "\n",
    "Ghadamiyan Lida 407 AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hzKzeQgui-CK"
   },
   "outputs": [],
   "source": [
    "# Loading the training data \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Train_Data = pd.read_csv(\"Project_Data\\\\training.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EhqI_vbdi-Ch"
   },
   "outputs": [],
   "source": [
    "# source: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "# Creating a dictionary by finding the occurrence of every word\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvect = CountVectorizer(ngram_range=(1, 1))   \n",
    "Train_Data_F = cvect.fit_transform(Train_Data[3].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MmW8bbiVi-Ci"
   },
   "outputs": [],
   "source": [
    "# Dividing the occurrences by the dictionary length to obtain term frequencies\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(norm= 'l2', use_idf= False)\n",
    "Train_Data_T = tfidf_transformer.fit_transform(Train_Data_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zs09eRh6i-Cj"
   },
   "outputs": [],
   "source": [
    "# Defining and fitting the model\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "Model_R1 = Ridge(alpha=1).fit(Train_Data_T, Train_Data[1])\n",
    "Model_R2 = Ridge(alpha=1).fit(Train_Data_T, Train_Data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ive0AF-ui-Cj"
   },
   "outputs": [],
   "source": [
    "# Loading the validation data and extracting features without including the data in the dictionary\n",
    "\n",
    "Validation_Data = pd.read_csv(\"Project_Data\\\\validation.txt\", header=None, encoding = 'latin-1')\n",
    "\n",
    "Validation_Data_F = cvect.transform(Validation_Data[3].values)\n",
    "Validation_Data_T = tfidf_transformer.transform(Validation_Data_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_jYMzRIqi-Ck"
   },
   "outputs": [],
   "source": [
    "# Prediction for validation data\n",
    "\n",
    "Prediction1 = Model_R1.predict(Validation_Data_T)\n",
    "Prediction2 = Model_R2.predict(Validation_Data_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "88tq9Sg0i-Ck",
    "outputId": "e92b1669-d5aa-4069-8d97-e7ee5990eea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE model 1 :  0.5221330793452222\n",
      "MAE model 2 :  0.6974568486309981\n",
      "\n",
      "MSE model 1 :  0.46333504055507857\n",
      "MSE model 2 :  0.8202959928306802\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model using Mean Absolute Error and Mean Squared Error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "MAE1 = mean_absolute_error(Validation_Data[1].values, Prediction1)\n",
    "MSE1 = mean_squared_error(Validation_Data[1].values, Prediction1)\n",
    "\n",
    "MAE2 = mean_absolute_error(Validation_Data[2].values, Prediction2)\n",
    "MSE2 = mean_squared_error(Validation_Data[2].values, Prediction2)\n",
    "\n",
    "print('MAE model 1 : ', MAE1)\n",
    "print('MAE model 2 : ', MAE2)\n",
    "\n",
    "print('\\nMSE model 1 : ', MSE1)\n",
    "print('MSE model 2 : ', MSE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CjpKmhXui-Cm"
   },
   "outputs": [],
   "source": [
    "# Concatenating the training and validation data in a new training file used for the final submission \n",
    "\n",
    "filenames = ['Project_Data\\\\training.txt','Project_Data\\\\validation.txt']\n",
    "with open('Project_Data\\\\my_training.txt', 'w', errors='ignore') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname, encoding='utf-8') as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "                \n",
    "Data = pd.read_csv(\"Project_Data\\\\my_training.txt\", encoding='latin-1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uMZEkryXi-Cn"
   },
   "outputs": [],
   "source": [
    "# Creating a new dictionary with the new trainig data \n",
    "\n",
    "Train_DataF = cvect.fit_transform(Data[3].values)\n",
    "Train_DataFF = tfidf_transformer.fit_transform(Train_DataF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OQ1RaSL7pFJA"
   },
   "outputs": [],
   "source": [
    "#  Defining and fitting the model \n",
    "\n",
    "Model_R1 = Ridge(alpha=1).fit(Train_DataFF, Data[1])\n",
    "Model_R2 = Ridge(alpha=1).fit(Train_DataFF, Data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WP9f6GxUi-Cq"
   },
   "outputs": [],
   "source": [
    "# Loading test data\n",
    "\n",
    "Test_Data = pd.read_csv(\"Project_Data\\\\test.txt\", header=None)\n",
    "\n",
    "Test_DataF = cvect.transform(Test_Data[1].values)\n",
    "Test_DataFF = tfidf_transformer.transform(Test_DataF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WIOd4LnupOlY"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "P1 = Model_R1.predict(Test_DataFF)\n",
    "P2 = Model_R2.predict(Test_DataFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V24RgZmhi-Cr"
   },
   "outputs": [],
   "source": [
    "# Creating the final submission in csv format\n",
    "\n",
    "final_df = pd.DataFrame({'id': Test_Data[0].values,\n",
    "                         'lat': P1,\n",
    "                         'long': P2\n",
    "                        })\n",
    "\n",
    "final_df.to_csv('FinalSubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lNZYR0Lwi-Cs",
    "outputId": "957f0e82-c0f6-4ee5-d30a-5791f9951e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 1st model :  -0.5136244050757868\n",
      "Best parameters 1st model :  {'Model_LR1__alpha': 1, 'cvect__ngram_range': (1, 1), 'tfidf_transformer__norm': 'l2', 'tfidf_transformer__use_idf': False}\n",
      "Best score 2nd model :  -0.6806272277821972\n",
      "Best parameters 2nd model :  {'Model_LR1__alpha': 1, 'cvect__ngram_range': (1, 1), 'tfidf_transformer__norm': 'l2', 'tfidf_transformer__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "# Grid search \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "text_clf = Pipeline([('cvect', CountVectorizer()), \n",
    "                     ('tfidf_transformer', TfidfTransformer()), \n",
    "                     ('Model_LR1', Ridge())])\n",
    " \n",
    "parameters = { 'cvect__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "              'tfidf_transformer__use_idf': (True, False), \n",
    "              'tfidf_transformer__norm': ('l1', 'l2'), \n",
    "              'Model_LR1__alpha': [0.1, 1, 2.2, 2.29, 3]}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, cv = 10, n_jobs = -1, scoring='neg_mean_absolute_error') \n",
    "grid_search.fit(Data[3].values, Data[1].values) \n",
    "\n",
    "print('Best score 1st model : ', grid_search.best_score_) \n",
    "print('Best parameters 1st model : ', grid_search.best_params_)\n",
    "\n",
    "grid_search2 = GridSearchCV(text_clf, parameters, cv = 10, n_jobs = -1, scoring='neg_mean_absolute_error') \n",
    "grid_search2.fit(Data[3].values, Data[2].values) \n",
    "\n",
    "print('Best score 2nd model : ', grid_search2.best_score_) \n",
    "print('Best parameters 2nd model : ', grid_search2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PML project",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
